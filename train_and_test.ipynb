{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(filename)\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"1006.png\n/kaggle/input/test-data/test/1006.png\n1147.png\n/kaggle/input/test-data/test/1147.png\n1025.png\n/kaggle/input/test-data/test/1025.png\n1386.png\n/kaggle/input/test-data/test/1386.png\n1286.png\n/kaggle/input/test-data/test/1286.png\n1626.png\n/kaggle/input/test-data/test/1626.png\n1660.png\n/kaggle/input/test-data/test/1660.png\n1267.png\n/kaggle/input/test-data/test/1267.png\n1514.png\n/kaggle/input/test-data/test/1514.png\n1158.png\n/kaggle/input/test-data/test/1158.png\n1013.png\n/kaggle/input/test-data/test/1013.png\n1696.png\n/kaggle/input/test-data/test/1696.png\n1082.png\n/kaggle/input/test-data/test/1082.png\n1538.png\n/kaggle/input/test-data/test/1538.png\n1470.png\n/kaggle/input/test-data/test/1470.png\n1909.png\n/kaggle/input/test-data/test/1909.png\n1144.png\n/kaggle/input/test-data/test/1144.png\n1577.png\n/kaggle/input/test-data/test/1577.png\n1977.png\n/kaggle/input/test-data/test/1977.png\n1031.png\n/kaggle/input/test-data/test/1031.png\n1596.png\n/kaggle/input/test-data/test/1596.png\n1875.png\n/kaggle/input/test-data/test/1875.png\n1714.png\n/kaggle/input/test-data/test/1714.png\n1258.png\n/kaggle/input/test-data/test/1258.png\n1694.png\n/kaggle/input/test-data/test/1694.png\n1317.png\n/kaggle/input/test-data/test/1317.png\n1783.png\n/kaggle/input/test-data/test/1783.png\n1619.png\n/kaggle/input/test-data/test/1619.png\n1564.png\n/kaggle/input/test-data/test/1564.png\n1605.png\n/kaggle/input/test-data/test/1605.png\n1141.png\n/kaggle/input/test-data/test/1141.png\n1816.png\n/kaggle/input/test-data/test/1816.png\n1506.png\n/kaggle/input/test-data/test/1506.png\n1754.png\n/kaggle/input/test-data/test/1754.png\n1999.png\n/kaggle/input/test-data/test/1999.png\n1931.png\n/kaggle/input/test-data/test/1931.png\n1752.png\n/kaggle/input/test-data/test/1752.png\n1425.png\n/kaggle/input/test-data/test/1425.png\n1811.png\n/kaggle/input/test-data/test/1811.png\n1800.png\n/kaggle/input/test-data/test/1800.png\n1563.png\n/kaggle/input/test-data/test/1563.png\n1134.png\n/kaggle/input/test-data/test/1134.png\n1068.png\n/kaggle/input/test-data/test/1068.png\n1903.png\n/kaggle/input/test-data/test/1903.png\n1523.png\n/kaggle/input/test-data/test/1523.png\n1740.png\n/kaggle/input/test-data/test/1740.png\n1347.png\n/kaggle/input/test-data/test/1347.png\n1125.png\n/kaggle/input/test-data/test/1125.png\n1682.png\n/kaggle/input/test-data/test/1682.png\n1004.png\n/kaggle/input/test-data/test/1004.png\n1787.png\n/kaggle/input/test-data/test/1787.png\n1567.png\n/kaggle/input/test-data/test/1567.png\n1186.png\n/kaggle/input/test-data/test/1186.png\n1407.png\n/kaggle/input/test-data/test/1407.png\n1951.png\n/kaggle/input/test-data/test/1951.png\n1678.png\n/kaggle/input/test-data/test/1678.png\n1034.png\n/kaggle/input/test-data/test/1034.png\n1627.png\n/kaggle/input/test-data/test/1627.png\n1359.png\n/kaggle/input/test-data/test/1359.png\n1712.png\n/kaggle/input/test-data/test/1712.png\n1329.png\n/kaggle/input/test-data/test/1329.png\n1056.png\n/kaggle/input/test-data/test/1056.png\n1819.png\n/kaggle/input/test-data/test/1819.png\n1403.png\n/kaggle/input/test-data/test/1403.png\n1693.png\n/kaggle/input/test-data/test/1693.png\n1603.png\n/kaggle/input/test-data/test/1603.png\n1196.png\n/kaggle/input/test-data/test/1196.png\n1502.png\n/kaggle/input/test-data/test/1502.png\n1507.png\n/kaggle/input/test-data/test/1507.png\n1662.png\n/kaggle/input/test-data/test/1662.png\n1478.png\n/kaggle/input/test-data/test/1478.png\n1707.png\n/kaggle/input/test-data/test/1707.png\n1341.png\n/kaggle/input/test-data/test/1341.png\n1938.png\n/kaggle/input/test-data/test/1938.png\n1486.png\n/kaggle/input/test-data/test/1486.png\n1039.png\n/kaggle/input/test-data/test/1039.png\n1413.png\n/kaggle/input/test-data/test/1413.png\n1706.png\n/kaggle/input/test-data/test/1706.png\n1543.png\n/kaggle/input/test-data/test/1543.png\n1242.png\n/kaggle/input/test-data/test/1242.png\n1076.png\n/kaggle/input/test-data/test/1076.png\n1431.png\n/kaggle/input/test-data/test/1431.png\n1283.png\n/kaggle/input/test-data/test/1283.png\n1188.png\n/kaggle/input/test-data/test/1188.png\n1687.png\n/kaggle/input/test-data/test/1687.png\n1493.png\n/kaggle/input/test-data/test/1493.png\n1254.png\n/kaggle/input/test-data/test/1254.png\n1033.png\n/kaggle/input/test-data/test/1033.png\n1023.png\n/kaggle/input/test-data/test/1023.png\n1340.png\n/kaggle/input/test-data/test/1340.png\n1379.png\n/kaggle/input/test-data/test/1379.png\n1601.png\n/kaggle/input/test-data/test/1601.png\n1185.png\n/kaggle/input/test-data/test/1185.png\n1733.png\n/kaggle/input/test-data/test/1733.png\n1509.png\n/kaggle/input/test-data/test/1509.png\n1604.png\n/kaggle/input/test-data/test/1604.png\n1324.png\n/kaggle/input/test-data/test/1324.png\n1581.png\n/kaggle/input/test-data/test/1581.png\n1919.png\n/kaggle/input/test-data/test/1919.png\n1238.png\n/kaggle/input/test-data/test/1238.png\n1632.png\n/kaggle/input/test-data/test/1632.png\n1455.png\n/kaggle/input/test-data/test/1455.png\n1102.png\n/kaggle/input/test-data/test/1102.png\n1253.png\n/kaggle/input/test-data/test/1253.png\n1888.png\n/kaggle/input/test-data/test/1888.png\n1881.png\n/kaggle/input/test-data/test/1881.png\n1934.png\n/kaggle/input/test-data/test/1934.png\n1371.png\n/kaggle/input/test-data/test/1371.png\n1229.png\n/kaggle/input/test-data/test/1229.png\n1201.png\n/kaggle/input/test-data/test/1201.png\n1257.png\n/kaggle/input/test-data/test/1257.png\n1587.png\n/kaggle/input/test-data/test/1587.png\n1373.png\n/kaggle/input/test-data/test/1373.png\n1572.png\n/kaggle/input/test-data/test/1572.png\n1181.png\n/kaggle/input/test-data/test/1181.png\n1342.png\n/kaggle/input/test-data/test/1342.png\n1786.png\n/kaggle/input/test-data/test/1786.png\n1095.png\n/kaggle/input/test-data/test/1095.png\n1735.png\n/kaggle/input/test-data/test/1735.png\n1208.png\n/kaggle/input/test-data/test/1208.png\ntrain_data.npy\n/kaggle/input/train-data/train_data.npy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np \nfrom PIL import Image  \nimport glob \nfrom glob import glob\nimport pickle\ntraining_dir = '/kaggle/input/test-data'\nfolders = glob(training_dir + '/*')\nprint(folders)\nfilelist1 = glob('/kaggle/input/test-data/test/*.png')\nmy_list = [] \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(filename)\n        \n        my_list.append(filename[:-4]) \n        \n        print(os.path.join(dirname, filename))\n \n\nprint(my_list) \n\nx = np.array([np.array([np.array(Image.open(fname)),[1,0,0]]) for fname in filelist1])\n\nz=np.asarray(my_list, dtype=None, order=None)\nz=z[:120]\nprint(z.size)\n\n","execution_count":2,"outputs":[{"output_type":"stream","text":"['/kaggle/input/test-data/test']\n1006.png\n/kaggle/input/test-data/test/1006.png\n1147.png\n/kaggle/input/test-data/test/1147.png\n1025.png\n/kaggle/input/test-data/test/1025.png\n1386.png\n/kaggle/input/test-data/test/1386.png\n1286.png\n/kaggle/input/test-data/test/1286.png\n1626.png\n/kaggle/input/test-data/test/1626.png\n1660.png\n/kaggle/input/test-data/test/1660.png\n1267.png\n/kaggle/input/test-data/test/1267.png\n1514.png\n/kaggle/input/test-data/test/1514.png\n1158.png\n/kaggle/input/test-data/test/1158.png\n1013.png\n/kaggle/input/test-data/test/1013.png\n1696.png\n/kaggle/input/test-data/test/1696.png\n1082.png\n/kaggle/input/test-data/test/1082.png\n1538.png\n/kaggle/input/test-data/test/1538.png\n1470.png\n/kaggle/input/test-data/test/1470.png\n1909.png\n/kaggle/input/test-data/test/1909.png\n1144.png\n/kaggle/input/test-data/test/1144.png\n1577.png\n/kaggle/input/test-data/test/1577.png\n1977.png\n/kaggle/input/test-data/test/1977.png\n1031.png\n/kaggle/input/test-data/test/1031.png\n1596.png\n/kaggle/input/test-data/test/1596.png\n1875.png\n/kaggle/input/test-data/test/1875.png\n1714.png\n/kaggle/input/test-data/test/1714.png\n1258.png\n/kaggle/input/test-data/test/1258.png\n1694.png\n/kaggle/input/test-data/test/1694.png\n1317.png\n/kaggle/input/test-data/test/1317.png\n1783.png\n/kaggle/input/test-data/test/1783.png\n1619.png\n/kaggle/input/test-data/test/1619.png\n1564.png\n/kaggle/input/test-data/test/1564.png\n1605.png\n/kaggle/input/test-data/test/1605.png\n1141.png\n/kaggle/input/test-data/test/1141.png\n1816.png\n/kaggle/input/test-data/test/1816.png\n1506.png\n/kaggle/input/test-data/test/1506.png\n1754.png\n/kaggle/input/test-data/test/1754.png\n1999.png\n/kaggle/input/test-data/test/1999.png\n1931.png\n/kaggle/input/test-data/test/1931.png\n1752.png\n/kaggle/input/test-data/test/1752.png\n1425.png\n/kaggle/input/test-data/test/1425.png\n1811.png\n/kaggle/input/test-data/test/1811.png\n1800.png\n/kaggle/input/test-data/test/1800.png\n1563.png\n/kaggle/input/test-data/test/1563.png\n1134.png\n/kaggle/input/test-data/test/1134.png\n1068.png\n/kaggle/input/test-data/test/1068.png\n1903.png\n/kaggle/input/test-data/test/1903.png\n1523.png\n/kaggle/input/test-data/test/1523.png\n1740.png\n/kaggle/input/test-data/test/1740.png\n1347.png\n/kaggle/input/test-data/test/1347.png\n1125.png\n/kaggle/input/test-data/test/1125.png\n1682.png\n/kaggle/input/test-data/test/1682.png\n1004.png\n/kaggle/input/test-data/test/1004.png\n1787.png\n/kaggle/input/test-data/test/1787.png\n1567.png\n/kaggle/input/test-data/test/1567.png\n1186.png\n/kaggle/input/test-data/test/1186.png\n1407.png\n/kaggle/input/test-data/test/1407.png\n1951.png\n/kaggle/input/test-data/test/1951.png\n1678.png\n/kaggle/input/test-data/test/1678.png\n1034.png\n/kaggle/input/test-data/test/1034.png\n1627.png\n/kaggle/input/test-data/test/1627.png\n1359.png\n/kaggle/input/test-data/test/1359.png\n1712.png\n/kaggle/input/test-data/test/1712.png\n1329.png\n/kaggle/input/test-data/test/1329.png\n1056.png\n/kaggle/input/test-data/test/1056.png\n1819.png\n/kaggle/input/test-data/test/1819.png\n1403.png\n/kaggle/input/test-data/test/1403.png\n1693.png\n/kaggle/input/test-data/test/1693.png\n1603.png\n/kaggle/input/test-data/test/1603.png\n1196.png\n/kaggle/input/test-data/test/1196.png\n1502.png\n/kaggle/input/test-data/test/1502.png\n1507.png\n/kaggle/input/test-data/test/1507.png\n1662.png\n/kaggle/input/test-data/test/1662.png\n1478.png\n/kaggle/input/test-data/test/1478.png\n1707.png\n/kaggle/input/test-data/test/1707.png\n1341.png\n/kaggle/input/test-data/test/1341.png\n1938.png\n/kaggle/input/test-data/test/1938.png\n1486.png\n/kaggle/input/test-data/test/1486.png\n1039.png\n/kaggle/input/test-data/test/1039.png\n1413.png\n/kaggle/input/test-data/test/1413.png\n1706.png\n/kaggle/input/test-data/test/1706.png\n1543.png\n/kaggle/input/test-data/test/1543.png\n1242.png\n/kaggle/input/test-data/test/1242.png\n1076.png\n/kaggle/input/test-data/test/1076.png\n1431.png\n/kaggle/input/test-data/test/1431.png\n1283.png\n/kaggle/input/test-data/test/1283.png\n1188.png\n/kaggle/input/test-data/test/1188.png\n1687.png\n/kaggle/input/test-data/test/1687.png\n1493.png\n/kaggle/input/test-data/test/1493.png\n1254.png\n/kaggle/input/test-data/test/1254.png\n1033.png\n/kaggle/input/test-data/test/1033.png\n1023.png\n/kaggle/input/test-data/test/1023.png\n1340.png\n/kaggle/input/test-data/test/1340.png\n1379.png\n/kaggle/input/test-data/test/1379.png\n1601.png\n/kaggle/input/test-data/test/1601.png\n1185.png\n/kaggle/input/test-data/test/1185.png\n1733.png\n/kaggle/input/test-data/test/1733.png\n1509.png\n/kaggle/input/test-data/test/1509.png\n1604.png\n/kaggle/input/test-data/test/1604.png\n1324.png\n/kaggle/input/test-data/test/1324.png\n1581.png\n/kaggle/input/test-data/test/1581.png\n1919.png\n/kaggle/input/test-data/test/1919.png\n1238.png\n/kaggle/input/test-data/test/1238.png\n1632.png\n/kaggle/input/test-data/test/1632.png\n1455.png\n/kaggle/input/test-data/test/1455.png\n1102.png\n/kaggle/input/test-data/test/1102.png\n1253.png\n/kaggle/input/test-data/test/1253.png\n1888.png\n/kaggle/input/test-data/test/1888.png\n1881.png\n/kaggle/input/test-data/test/1881.png\n1934.png\n/kaggle/input/test-data/test/1934.png\n1371.png\n/kaggle/input/test-data/test/1371.png\n1229.png\n/kaggle/input/test-data/test/1229.png\n1201.png\n/kaggle/input/test-data/test/1201.png\n1257.png\n/kaggle/input/test-data/test/1257.png\n1587.png\n/kaggle/input/test-data/test/1587.png\n1373.png\n/kaggle/input/test-data/test/1373.png\n1572.png\n/kaggle/input/test-data/test/1572.png\n1181.png\n/kaggle/input/test-data/test/1181.png\n1342.png\n/kaggle/input/test-data/test/1342.png\n1786.png\n/kaggle/input/test-data/test/1786.png\n1095.png\n/kaggle/input/test-data/test/1095.png\n1735.png\n/kaggle/input/test-data/test/1735.png\n1208.png\n/kaggle/input/test-data/test/1208.png\ntrain_data.npy\n/kaggle/input/train-data/train_data.npy\n['1006', '1147', '1025', '1386', '1286', '1626', '1660', '1267', '1514', '1158', '1013', '1696', '1082', '1538', '1470', '1909', '1144', '1577', '1977', '1031', '1596', '1875', '1714', '1258', '1694', '1317', '1783', '1619', '1564', '1605', '1141', '1816', '1506', '1754', '1999', '1931', '1752', '1425', '1811', '1800', '1563', '1134', '1068', '1903', '1523', '1740', '1347', '1125', '1682', '1004', '1787', '1567', '1186', '1407', '1951', '1678', '1034', '1627', '1359', '1712', '1329', '1056', '1819', '1403', '1693', '1603', '1196', '1502', '1507', '1662', '1478', '1707', '1341', '1938', '1486', '1039', '1413', '1706', '1543', '1242', '1076', '1431', '1283', '1188', '1687', '1493', '1254', '1033', '1023', '1340', '1379', '1601', '1185', '1733', '1509', '1604', '1324', '1581', '1919', '1238', '1632', '1455', '1102', '1253', '1888', '1881', '1934', '1371', '1229', '1201', '1257', '1587', '1373', '1572', '1181', '1342', '1786', '1095', '1735', '1208', 'train_data']\n120\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import cv2#reading and resizing                 \nimport numpy as np#arrays         \nimport os#dealing with directories                  \nfrom random import shuffle #to shuffle data\nfrom tqdm import tqdm#loop progress bar  \nfrom sklearn.metrics import roc_auc_score    \nimport matplotlib.pyplot as plt # for visualizations\nimport tensorflow as tf # For tensor operations\nimport pandas as pd # for manipulating data\nimport zipfile\nimport os, sys\nfrom glob import glob\nfrom glob import glob\ntraining_dir = '/kaggle/input'\n\n\nfolders = glob(training_dir + '/*')\nprint(folders)\n\nIMG_SIZE = 80\ntest_size=1\nepochs = 100\nstep_size = 8\nIMG_SIZE_ALEXNET = 227\nvalidating_size = 40\nnodes_fc1 = 4096\nnodes_fc2 = 4096\noutput_classes = 3\n\nTRAIN_DIR = os.getcwd()\n\n\n\nprint(TRAIN_DIR) \n\ntrain_data = np.load('/kaggle/input/train-data/train_data.npy',allow_pickle=True)\n\ntest_data = x\n\nfor i in range(len(train_data)):\n    train_data[i][0] = cv2.resize(np.float32(train_data[i][0]),(IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET))\n\nfor i in range(len(test_data)):\n    test_data[i][0] = cv2.resize(np.float32(test_data[i][0]),(IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET))\n\ntrain = train_data[:1400]\ncv = train_data[1400:]\n\nX = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3)\nY = np.array([i[1] for i in train])\n\ncv_x = np.array([i[0] for i in cv]).reshape(-1,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3)\ncv_y = np.array([i[1] for i in cv])\ntest_x = np.array([i[0] for i in test_data]).reshape(-1,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3)\ntest_y = np.array([i[1] for i in test_data])\n\nprint(X.shape)\n\nprint(Y.shape)\n\nprint(cv_x.shape)\n\nprint(test_x.shape)\n\nsteps = len(train)\nprint(steps)\nremaining = steps % step_size\n\n\ntf.reset_default_graph()\n\n\nx = tf.placeholder(tf.float32,shape=[None,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3])\ny_true = tf.placeholder(tf.float32,shape=[None,output_classes])\n\n\nw_1 = tf.Variable(tf.truncated_normal([11,11,3,96], stddev=0.01))\n\nb_1 = tf.Variable(tf.constant(0.0, shape=[[11,11,3,96][3]]))\n\nc_1 = tf.nn.conv2d(x, w_1,strides=[1, 4, 4, 1], padding='VALID')\n\nc_1 = c_1 + b_1\n\nc_1 = tf.nn.relu(c_1)\n\nprint(c_1)\n\np_1 = tf.nn.max_pool(c_1, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\nprint(p_1)\n\n\nw_2 = tf.Variable(tf.truncated_normal([5,5,96,256], stddev=0.01))\n\nb_2 = tf.Variable(tf.constant(1.0, shape=[[5,5,96,256][3]]))\n\nc_2 = tf.nn.conv2d(p_1, w_2,strides=[1, 1, 1, 1], padding='SAME')\n\nc_2 = c_2 + b_2\n\nc_2 = tf.nn.relu(c_2)\n\nprint(c_2)\n\n\np_2 = tf.nn.max_pool(c_2, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\nprint(p_2)\n\n\nw_3 = tf.Variable(tf.truncated_normal([3, 3, 256, 384], stddev=0.01))\n\nb_3 = tf.Variable(tf.constant(0.0, shape=[[3, 3, 256, 384][3]]))\n\nc_3 = tf.nn.conv2d(p_2, w_3,strides=[1, 1, 1, 1], padding='SAME')\n\nc_3 = c_3 + b_3\n\nc_3 = tf.nn.relu(c_3)\n\nprint(c_3)\n\n\nw_4 = tf.Variable(tf.truncated_normal([3, 3, 384, 384], stddev=0.01))\n\nb_4 = tf.Variable(tf.constant(0.0, shape=[[3, 3, 384, 384][3]]))\n\nc_4 = tf.nn.conv2d(c_3, w_4,strides=[1, 1, 1, 1], padding='SAME')\n\nc_4 = c_4 + b_4\n\nc_4 = tf.nn.relu(c_4)\n\nprint(c_4)\n\n\nw_5 = tf.Variable(tf.truncated_normal([3, 3, 384, 256], stddev=0.01))\n\nb_5 = tf.Variable(tf.constant(0.0, shape=[[3, 3, 384, 256][3]]))\n\nc_5 = tf.nn.conv2d(c_4, w_5,strides=[1, 1, 1, 1], padding='SAME')\n\nc_5 = c_5 + b_5\n\nc_5 = tf.nn.relu(c_5)\n\nprint(c_5)\n\n\np_3 = tf.nn.max_pool(c_5, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\nprint(p_3)\n\n\nflattened = tf.reshape(p_3,[-1,6*6*256])\nprint(flattened)\n\n\ninput_size = int( flattened.get_shape()[1] )\n\nw1_fc = tf.Variable(tf.truncated_normal([input_size, nodes_fc1], stddev=0.01))\n\nb1_fc = tf.Variable( tf.constant(1.0, shape=[nodes_fc1] ) )\n\ns_fc1 = tf.matmul(flattened, w1_fc) + b1_fc\n\ns_fc1 = tf.nn.relu(s_fc1)\n\n\nhold_prob1 = tf.placeholder(tf.float32)\ns_fc1 = tf.nn.dropout(s_fc1,keep_prob=hold_prob1)\n\nprint(s_fc1)\n\n\nw2_fc = tf.Variable(tf.truncated_normal([nodes_fc1, nodes_fc2], stddev=0.01))\n\nb2_fc = tf.Variable( tf.constant(1.0, shape=[nodes_fc2] ) )\n\ns_fc2 = tf.matmul(s_fc1, w2_fc) + b2_fc\n\ns_fc2 = tf.nn.relu(s_fc2)\nprint(s_fc2)\n\n\nhold_prob2 = tf.placeholder(tf.float32)\ns_fc2 = tf.nn.dropout(s_fc2,keep_prob=hold_prob1)\n\n\nw3_fc = tf.Variable(tf.truncated_normal([nodes_fc2,output_classes], stddev=0.01))\n\nb3_fc = tf.Variable( tf.constant(1.0, shape=[output_classes] ) )\n\ny_pred = tf.matmul(s_fc2, w3_fc) + b3_fc\n\nprint(y_pred)\n\n\n\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))\n\n\ntrain = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(cross_entropy)\n\n\nmatches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\nacc = tf.reduce_mean(tf.cast(matches,tf.float32))\n\n\ninit = tf.global_variables_initializer()\n\n\nacc_list = []\nauc_list = []\nloss_list = []\nsaver = tf.train.Saver()\n\n\nconfig = tf.ConfigProto(allow_soft_placement=True)\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.allocator_type = 'BFC'\n\n\n\n\n\n\n\n\n\n","execution_count":3,"outputs":[{"output_type":"stream","text":"['/kaggle/input/test-data', '/kaggle/input/train-data']\n/kaggle/working\n(1400, 227, 227, 3)\n(1400, 3)\n(100, 227, 227, 3)\n(120, 227, 227, 3)\n1400\nTensor(\"Relu:0\", shape=(?, 55, 55, 96), dtype=float32)\nTensor(\"MaxPool:0\", shape=(?, 27, 27, 96), dtype=float32)\nTensor(\"Relu_1:0\", shape=(?, 27, 27, 256), dtype=float32)\nTensor(\"MaxPool_1:0\", shape=(?, 13, 13, 256), dtype=float32)\nTensor(\"Relu_2:0\", shape=(?, 13, 13, 384), dtype=float32)\nTensor(\"Relu_3:0\", shape=(?, 13, 13, 384), dtype=float32)\nTensor(\"Relu_4:0\", shape=(?, 13, 13, 256), dtype=float32)\nTensor(\"MaxPool_2:0\", shape=(?, 6, 6, 256), dtype=float32)\nTensor(\"Reshape:0\", shape=(?, 9216), dtype=float32)\nTensor(\"dropout/mul_1:0\", shape=(?, 4096), dtype=float32)\nTensor(\"Relu_6:0\", shape=(?, 4096), dtype=float32)\nTensor(\"add_7:0\", shape=(?, 3), dtype=float32)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session(config=config) as sess:\n    sess.run(init)\n    for i in range(epochs):\n        print(i)\n        for j in range(0,steps-remaining,step_size):\n            \n            _,c = sess.run([train,cross_entropy],\n            feed_dict={x:X[j:j+step_size] , y_true:Y[j:j+step_size],hold_prob1:0.5,hold_prob2:0.5})\n        \n        \n\n        cv_auc_list = []\n        cv_acc_list = []\n        cv_loss_list = []\n        for v in range(0,len(cv_x)-int(len(cv_x) % validating_size),validating_size):\n            acc_on_cv,loss_on_cv,preds = sess.run([acc,cross_entropy,tf.nn.softmax(y_pred)],\n            feed_dict={x:cv_x[v:v+validating_size] ,y_true:cv_y[v:v+validating_size] ,hold_prob1:1.0,hold_prob2:1.0})\n\n            auc_on_cv = roc_auc_score(cv_y[v:v+validating_size],preds)\n            cv_acc_list.append(acc_on_cv)\n            cv_auc_list.append(auc_on_cv)\n            cv_loss_list.append(loss_on_cv)\n        acc_cv_ = round(np.mean(cv_acc_list),5)\n        auc_cv_ = round(np.mean(cv_auc_list),5)\n        loss_cv_ = round(np.mean(cv_loss_list),5)\n        acc_list.append(acc_cv_)\n        auc_list.append(auc_cv_)\n        loss_list.append(loss_cv_)\n        print(\"Epoch:\",i,\"Accuracy:\",acc_cv_,\"Loss:\",loss_cv_ ,\"AUC:\",auc_cv_)\n    \n    jj=np.zeros((120,1))\n    for v in range(0,len(test_x)-int(len(test_x) % test_size),test_size):\n        preds = sess.run([tf.nn.softmax(y_pred)],\n        feed_dict={x:test_x[v:v+test_size] ,hold_prob1:1.0,hold_prob2:1.0})\n        \n        \n        print(z[v])\n        k=np.asarray(preds, dtype=None, order=None)\n        if(np.argmax(k)==0):\n            f=1\n        if(np.argmax(k)==1):\n            f=3\n        if(np.argmax(k)==2):\n            f=2   \n      \n        print(f)\n        jj[v,0]=f\n\n    ","execution_count":4,"outputs":[{"output_type":"stream","text":"0\nEpoch: 0 Accuracy: 0.8125 Loss: 0.43695 AUC: 0.96865\n1\nEpoch: 1 Accuracy: 0.85 Loss: 0.31727 AUC: 0.99346\n2\nEpoch: 2 Accuracy: 0.925 Loss: 0.18516 AUC: 0.98869\n3\nEpoch: 3 Accuracy: 0.925 Loss: 0.1841 AUC: 0.98871\n4\nEpoch: 4 Accuracy: 0.9625 Loss: 0.1683 AUC: 0.98869\n5\nEpoch: 5 Accuracy: 0.9125 Loss: 0.17433 AUC: 0.99044\n6\nEpoch: 6 Accuracy: 0.9625 Loss: 0.14368 AUC: 0.99088\n7\nEpoch: 7 Accuracy: 0.9375 Loss: 0.14355 AUC: 0.99131\n8\nEpoch: 8 Accuracy: 0.95 Loss: 0.13767 AUC: 0.99131\n9\nEpoch: 9 Accuracy: 0.95 Loss: 0.12495 AUC: 0.99219\n10\nEpoch: 10 Accuracy: 0.8875 Loss: 0.25486 AUC: 0.99219\n11\nEpoch: 11 Accuracy: 0.95 Loss: 0.12677 AUC: 0.99218\n12\nEpoch: 12 Accuracy: 0.9625 Loss: 0.11046 AUC: 0.99306\n13\nEpoch: 13 Accuracy: 0.9625 Loss: 0.12082 AUC: 0.99349\n14\nEpoch: 14 Accuracy: 0.95 Loss: 0.14529 AUC: 0.99306\n15\nEpoch: 15 Accuracy: 0.975 Loss: 0.12181 AUC: 0.99306\n16\nEpoch: 16 Accuracy: 0.975 Loss: 0.10499 AUC: 0.99479\n17\nEpoch: 17 Accuracy: 0.9625 Loss: 0.08554 AUC: 0.99653\n18\nEpoch: 18 Accuracy: 0.95 Loss: 0.11299 AUC: 0.99305\n19\nEpoch: 19 Accuracy: 0.925 Loss: 0.16386 AUC: 0.99305\n20\nEpoch: 20 Accuracy: 0.925 Loss: 0.15505 AUC: 0.99524\n21\nEpoch: 21 Accuracy: 0.975 Loss: 0.11993 AUC: 0.99349\n22\nEpoch: 22 Accuracy: 0.925 Loss: 0.15945 AUC: 0.99566\n23\nEpoch: 23 Accuracy: 0.9375 Loss: 0.1363 AUC: 0.99478\n24\nEpoch: 24 Accuracy: 0.9625 Loss: 0.12112 AUC: 0.9974\n25\nEpoch: 25 Accuracy: 0.925 Loss: 0.16805 AUC: 0.99306\n26\nEpoch: 26 Accuracy: 0.9125 Loss: 0.26622 AUC: 0.99785\n27\nEpoch: 27 Accuracy: 0.9625 Loss: 0.11373 AUC: 0.99826\n28\nEpoch: 28 Accuracy: 0.9625 Loss: 0.1125 AUC: 0.9974\n29\nEpoch: 29 Accuracy: 0.9625 Loss: 0.0961 AUC: 0.99913\n30\nEpoch: 30 Accuracy: 0.975 Loss: 0.10012 AUC: 0.99826\n31\nEpoch: 31 Accuracy: 0.95 Loss: 0.17933 AUC: 0.99479\n32\nEpoch: 32 Accuracy: 0.9625 Loss: 0.14525 AUC: 0.9974\n33\nEpoch: 33 Accuracy: 0.9625 Loss: 0.17192 AUC: 0.99653\n34\nEpoch: 34 Accuracy: 0.9375 Loss: 0.13302 AUC: 0.99826\n35\nEpoch: 35 Accuracy: 0.9625 Loss: 0.156 AUC: 0.99608\n36\nEpoch: 36 Accuracy: 0.9625 Loss: 0.12273 AUC: 0.99826\n37\nEpoch: 37 Accuracy: 0.9625 Loss: 0.10658 AUC: 0.99826\n38\nEpoch: 38 Accuracy: 0.975 Loss: 0.07836 AUC: 0.9974\n39\nEpoch: 39 Accuracy: 0.95 Loss: 0.13812 AUC: 0.99913\n40\nEpoch: 40 Accuracy: 0.9625 Loss: 0.14021 AUC: 0.99826\n41\nEpoch: 41 Accuracy: 0.9625 Loss: 0.18045 AUC: 0.99478\n42\nEpoch: 42 Accuracy: 0.975 Loss: 0.14337 AUC: 0.99826\n43\nEpoch: 43 Accuracy: 0.9625 Loss: 0.11736 AUC: 0.99913\n44\nEpoch: 44 Accuracy: 0.9625 Loss: 0.19527 AUC: 0.99609\n45\nEpoch: 45 Accuracy: 0.9625 Loss: 0.12482 AUC: 0.9974\n46\nEpoch: 46 Accuracy: 0.9625 Loss: 0.19299 AUC: 0.99609\n47\nEpoch: 47 Accuracy: 0.9625 Loss: 0.16442 AUC: 0.99653\n48\nEpoch: 48 Accuracy: 0.9625 Loss: 0.13334 AUC: 0.99826\n49\nEpoch: 49 Accuracy: 0.95 Loss: 0.19181 AUC: 0.99044\n50\nEpoch: 50 Accuracy: 0.95 Loss: 0.17548 AUC: 0.99783\n51\nEpoch: 51 Accuracy: 0.95 Loss: 0.24123 AUC: 0.99826\n52\nEpoch: 52 Accuracy: 0.8875 Loss: 0.38972 AUC: 0.99566\n53\nEpoch: 53 Accuracy: 0.9625 Loss: 0.13752 AUC: 0.99739\n54\nEpoch: 54 Accuracy: 0.975 Loss: 0.13779 AUC: 0.99826\n55\nEpoch: 55 Accuracy: 0.9625 Loss: 0.17352 AUC: 0.99826\n56\nEpoch: 56 Accuracy: 0.975 Loss: 0.16328 AUC: 0.9974\n57\nEpoch: 57 Accuracy: 0.9625 Loss: 0.1315 AUC: 0.99913\n58\nEpoch: 58 Accuracy: 0.95 Loss: 0.18737 AUC: 0.99738\n59\nEpoch: 59 Accuracy: 0.9625 Loss: 0.20655 AUC: 0.99696\n60\nEpoch: 60 Accuracy: 0.95 Loss: 0.16397 AUC: 0.99262\n61\nEpoch: 61 Accuracy: 0.9625 Loss: 0.09633 AUC: 0.99913\n62\nEpoch: 62 Accuracy: 0.9625 Loss: 0.17499 AUC: 0.99913\n63\nEpoch: 63 Accuracy: 0.9625 Loss: 0.09547 AUC: 0.99913\n64\nEpoch: 64 Accuracy: 0.975 Loss: 0.12134 AUC: 0.99826\n65\nEpoch: 65 Accuracy: 0.975 Loss: 0.11556 AUC: 0.99913\n66\nEpoch: 66 Accuracy: 0.975 Loss: 0.1236 AUC: 0.99826\n67\nEpoch: 67 Accuracy: 0.975 Loss: 0.13469 AUC: 0.99913\n68\nEpoch: 68 Accuracy: 0.9625 Loss: 0.1939 AUC: 0.99392\n69\nEpoch: 69 Accuracy: 0.975 Loss: 0.11184 AUC: 0.99826\n70\nEpoch: 70 Accuracy: 0.975 Loss: 0.08605 AUC: 0.99826\n71\nEpoch: 71 Accuracy: 0.975 Loss: 0.04708 AUC: 0.99826\n72\nEpoch: 72 Accuracy: 0.975 Loss: 0.15938 AUC: 0.99826\n73\nEpoch: 73 Accuracy: 0.9875 Loss: 0.12572 AUC: 0.99826\n74\nEpoch: 74 Accuracy: 0.9375 Loss: 0.33201 AUC: 0.99173\n75\nEpoch: 75 Accuracy: 0.975 Loss: 0.127 AUC: 0.9974\n76\nEpoch: 76 Accuracy: 0.95 Loss: 0.19377 AUC: 0.9987\n77\nEpoch: 77 Accuracy: 0.9625 Loss: 0.16198 AUC: 0.99783\n78\nEpoch: 78 Accuracy: 0.95 Loss: 0.30062 AUC: 0.9974\n79\nEpoch: 79 Accuracy: 0.9875 Loss: 0.11453 AUC: 0.99783\n80\nEpoch: 80 Accuracy: 0.975 Loss: 0.11875 AUC: 0.99826\n81\nEpoch: 81 Accuracy: 0.9625 Loss: 0.14055 AUC: 0.99826\n82\nEpoch: 82 Accuracy: 0.975 Loss: 0.11575 AUC: 0.99913\n83\nEpoch: 83 Accuracy: 0.975 Loss: 0.11139 AUC: 0.99913\n84\nEpoch: 84 Accuracy: 0.975 Loss: 0.12307 AUC: 0.99913\n85\nEpoch: 85 Accuracy: 0.975 Loss: 0.12092 AUC: 0.99913\n86\nEpoch: 86 Accuracy: 0.975 Loss: 0.12073 AUC: 0.99913\n87\nEpoch: 87 Accuracy: 0.975 Loss: 0.12123 AUC: 0.99913\n88\nEpoch: 88 Accuracy: 0.9375 Loss: 0.32273 AUC: 0.99826\n89\nEpoch: 89 Accuracy: 0.95 Loss: 0.23218 AUC: 0.99434\n90\nEpoch: 90 Accuracy: 0.9625 Loss: 0.13691 AUC: 0.9974\n91\nEpoch: 91 Accuracy: 0.975 Loss: 0.14777 AUC: 0.99826\n92\nEpoch: 92 Accuracy: 0.9625 Loss: 0.19268 AUC: 0.9974\n93\nEpoch: 93 Accuracy: 0.975 Loss: 0.11642 AUC: 0.99826\n94\nEpoch: 94 Accuracy: 0.9625 Loss: 0.12316 AUC: 0.99913\n95\nEpoch: 95 Accuracy: 0.975 Loss: 0.11302 AUC: 0.99913\n96\nEpoch: 96 Accuracy: 0.975 Loss: 0.12865 AUC: 0.9987\n97\nEpoch: 97 Accuracy: 0.9875 Loss: 0.13211 AUC: 0.99826\n98\nEpoch: 98 Accuracy: 0.9875 Loss: 0.11688 AUC: 0.99826\n99\nEpoch: 99 Accuracy: 0.975 Loss: 0.18945 AUC: 0.99826\n1006\n1\n1147\n1\n1025\n1\n1386\n3\n1286\n2\n1626\n1\n1660\n2\n1267\n1\n1514\n1\n1158\n2\n1013\n3\n1696\n1\n1082\n1\n1538\n2\n1470\n3\n1909\n2\n1144\n3\n1577\n1\n1977\n3\n1031\n2\n1596\n2\n1875\n2\n1714\n3\n1258\n3\n1694\n1\n1317\n1\n1783\n2\n1619\n1\n1564\n1\n1605\n3\n1141\n1\n1816\n1\n1506\n3\n1754\n2\n1999\n3\n1931\n1\n1752\n2\n1425\n1\n1811\n3\n1800\n3\n1563\n2\n1134\n2\n1068\n2\n1903\n3\n1523\n2\n1740\n1\n1347\n3\n1125\n1\n1682\n1\n1004\n3\n1787\n1\n1567\n2\n1186\n2\n1407\n3\n1951\n2\n1678\n2\n1034\n2\n1627\n3\n1359\n3\n1712\n3\n1329\n1\n1056\n1\n1819\n1\n1403\n2\n1693\n2\n1603\n2\n1196\n3\n1502\n3\n1507\n2\n1662\n3\n1478\n2\n1707\n1\n1341\n2\n1938\n2\n1486\n3\n1039\n1\n1413\n1\n1706\n3\n1543\n2\n1242\n3\n1076\n1\n1431\n1\n1283\n1\n1188\n3\n1687\n1\n1493\n2\n1254\n3\n1033\n3\n1023\n2\n1340\n3\n1379\n2\n1601\n3\n1185\n3\n1733\n3\n1509\n2\n1604\n1\n1324\n2\n1581\n1\n1919\n3\n1238\n2\n1632\n2\n1455\n3\n1102\n3\n1253\n2\n1888\n3\n1881\n1\n1934\n2\n1371\n1\n1229\n3\n1201\n1\n1257\n3\n1587\n1\n1373\n1\n1572\n1\n1181\n1\n1342\n2\n1786\n3\n1095\n2\n1735\n2\n1208\n1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\njj=np.resize(jj,(120,1))\nz=np.resize(z,(120,1))\nl=np.concatenate((z, jj), axis=1)\n\n\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\ndata2 = np.array(['ImageId','label'])\n\n\ndf = pd.DataFrame(columns=data2,data=l)\n\ncreate_download_link(df)\n","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a download=\"data.csv\" href=\"data:text/csv;base64,SW1hZ2VJZCxsYWJlbAoxMDA2LDEuMAoxMTQ3LDEuMAoxMDI1LDEuMAoxMzg2LDMuMAoxMjg2LDIuMAoxNjI2LDEuMAoxNjYwLDIuMAoxMjY3LDEuMAoxNTE0LDEuMAoxMTU4LDIuMAoxMDEzLDMuMAoxNjk2LDEuMAoxMDgyLDEuMAoxNTM4LDIuMAoxNDcwLDMuMAoxOTA5LDIuMAoxMTQ0LDMuMAoxNTc3LDEuMAoxOTc3LDMuMAoxMDMxLDIuMAoxNTk2LDIuMAoxODc1LDIuMAoxNzE0LDMuMAoxMjU4LDMuMAoxNjk0LDEuMAoxMzE3LDEuMAoxNzgzLDIuMAoxNjE5LDEuMAoxNTY0LDEuMAoxNjA1LDMuMAoxMTQxLDEuMAoxODE2LDEuMAoxNTA2LDMuMAoxNzU0LDIuMAoxOTk5LDMuMAoxOTMxLDEuMAoxNzUyLDIuMAoxNDI1LDEuMAoxODExLDMuMAoxODAwLDMuMAoxNTYzLDIuMAoxMTM0LDIuMAoxMDY4LDIuMAoxOTAzLDMuMAoxNTIzLDIuMAoxNzQwLDEuMAoxMzQ3LDMuMAoxMTI1LDEuMAoxNjgyLDEuMAoxMDA0LDMuMAoxNzg3LDEuMAoxNTY3LDIuMAoxMTg2LDIuMAoxNDA3LDMuMAoxOTUxLDIuMAoxNjc4LDIuMAoxMDM0LDIuMAoxNjI3LDMuMAoxMzU5LDMuMAoxNzEyLDMuMAoxMzI5LDEuMAoxMDU2LDEuMAoxODE5LDEuMAoxNDAzLDIuMAoxNjkzLDIuMAoxNjAzLDIuMAoxMTk2LDMuMAoxNTAyLDMuMAoxNTA3LDIuMAoxNjYyLDMuMAoxNDc4LDIuMAoxNzA3LDEuMAoxMzQxLDIuMAoxOTM4LDIuMAoxNDg2LDMuMAoxMDM5LDEuMAoxNDEzLDEuMAoxNzA2LDMuMAoxNTQzLDIuMAoxMjQyLDMuMAoxMDc2LDEuMAoxNDMxLDEuMAoxMjgzLDEuMAoxMTg4LDMuMAoxNjg3LDEuMAoxNDkzLDIuMAoxMjU0LDMuMAoxMDMzLDMuMAoxMDIzLDIuMAoxMzQwLDMuMAoxMzc5LDIuMAoxNjAxLDMuMAoxMTg1LDMuMAoxNzMzLDMuMAoxNTA5LDIuMAoxNjA0LDEuMAoxMzI0LDIuMAoxNTgxLDEuMAoxOTE5LDMuMAoxMjM4LDIuMAoxNjMyLDIuMAoxNDU1LDMuMAoxMTAyLDMuMAoxMjUzLDIuMAoxODg4LDMuMAoxODgxLDEuMAoxOTM0LDIuMAoxMzcxLDEuMAoxMjI5LDMuMAoxMjAxLDEuMAoxMjU3LDMuMAoxNTg3LDEuMAoxMzczLDEuMAoxNTcyLDEuMAoxMTgxLDEuMAoxMzQyLDIuMAoxNzg2LDMuMAoxMDk1LDIuMAoxNzM1LDIuMAoxMjA4LDEuMAo=\" target=\"_blank\">Download CSV file</a>"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}